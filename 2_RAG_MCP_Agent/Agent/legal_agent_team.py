import streamlit as st
from dotenv import load_dotenv
import os
import tempfile

from agno.agent import Agent
from agno.team import Team
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.vectordb.qdrant import Qdrant
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.pdf_reader import PDFReader
from agno.knowledge.chunking.document import DocumentChunking

def init_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€å˜é‡"""
    st.session_state.openai_api_key = os.getenv("API_KEY", None)
    st.session_state.openai_base_url = os.getenv("BASE_URL", None)
    st.session_state.qdrant_api_key = os.getenv("QDRANT_API_KEY", None)
    st.session_state.qdrant_url = os.getenv("QDRANT_URL", None)
    st.session_state.vector_db = None
    st.session_state.legal_team = None
    st.session_state.knowledge_base = None
    st.session_state.processed_files = set()

COLLECTION_NAME = "legal_documents"

def init_qdrant():
    """åˆå§‹åŒ– Qdrant å‘é‡æ•°æ®åº“è¿æ¥"""
    if not all([st.session_state.qdrant_api_key, st.session_state.qdrant_url]):
        return None
    try:
        vector_db = Qdrant(
            collection=COLLECTION_NAME,
            api_key=st.session_state.qdrant_api_key,
            url=st.session_state.qdrant_url,
            embedder=OpenAIEmbedder(
                id="text-embedding-3-small",
                api_key=st.session_state.openai_api_key,
                base_url=st.session_state.openai_base_url
            )
        )
        return vector_db
    except Exception as e: 
        st.error(f"åˆå§‹åŒ– Qdrant æ—¶å‡ºé”™: {e}")
        return None
    
def process_document(upload_file, vector_db: Qdrant):
    if not all([st.session_state.openai_api_key, st.session_state.openai_base_url]):
        st.error("å¿…é¡»è®¾ç½® OpenAI API å¯†é’¥å’ŒåŸºç¡€ URLã€‚")
        return None
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(upload_file.read())
            tmp_file_path = tmp_file.name

        st.info("æ­£åœ¨åŠ è½½å’Œå¤„ç†æ–‡æ¡£...")
        
        knowledge = Knowledge(
            vector_db=vector_db
        )

        with st.spinner("ğŸ“¤ æ­£åœ¨å°†æ–‡æ¡£åŠ è½½åˆ°çŸ¥è¯†åº“ä¸­..."):
            try:
                knowledge.add_content(
                    path=tmp_file_path,
                    reader=PDFReader(
                        name="æ–‡æ¡£åˆ†å—é˜…è¯»å™¨",
                        chunking_stategy=DocumentChunking(
                            chunk_size=1000,
                            overlap=200
                        )
                    )
                )
            except Exception as e:
                st.error(f"åŠ è½½æ–‡æ¡£æ—¶å‡ºé”™: {str(e)}")
            try:
                os.unlink(tmp_file_path)
            except:
                pass

            return knowledge
    except Exception as e:
        st.error(f"æ–‡æ¡£å¤„ç†é”™è¯¯: {str(e)}")
        raise Exception(f"å¤„ç†æ–‡æ¡£æ—¶å‡ºé”™: {str(e)}")



def main():
    st.set_page_config(page_title="æ³•å¾‹æ–‡ä»¶åˆ†æå™¨", layout="wide")
    load_dotenv()
    init_session_state()

    st.title("AI æ³•å¾‹æ™ºèƒ½ä½“å›¢é˜Ÿ ğŸ‘¨â€âš–ï¸")
    with st.sidebar:
        st.header("ğŸ”‘ API é…ç½®")
        openai_key = st.text_input(
            "OpenAI API å¯†é’¥",
            type="password",
            value= st.session_state.openai_api_key if st.session_state.openai_api_key else "",
            help="è¾“å…¥æ‚¨çš„ OpenAI API å¯†é’¥"
        )
        if openai_key:
            st.session_state.openai_api_key = openai_key
        
        openai_url = st.text_input(
            "OpenAI åŸºç¡€ URL",
            type="password",
            value = st.session_state.openai_base_url if st.session_state.openai_base_url else "",
            help="è¾“å…¥æ‚¨çš„ OpenAI åŸºç¡€ URL"
        )
        if openai_url:
            st.session_state.openai_base_url = openai_url

        qdrant_key = st.text_input(
            "Qdrant API å¯†é’¥",
            type="password",
            value= st.session_state.qdrant_api_key if st.session_state.qdrant_api_key else "",
            help="è¾“å…¥æ‚¨çš„ Qdrant API å¯†é’¥"
        )
        if qdrant_key:
            st.session_state.qdrant_api_key = qdrant_key
        
        qdrant_url = st.text_input(
            "Qdrant URL",
            type="password",
            value=st.session_state.qdrant_url if st.session_state.qdrant_url else "",
            help="è¾“å…¥æ‚¨çš„ Qdrant URL"
        )
        if qdrant_url:
            st.session_state.qdrant_url = qdrant_url
        
        if all([st.session_state.qdrant_api_key, st.session_state.qdrant_url]):
            try:
                if not st.session_state.vector_db:
                    st.session_state.vector_db = init_qdrant()
                    if st.session_state.vector_db:
                        st.success("Qdrant å‘é‡æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸï¼")
            except Exception as e:
                st.error(f"è¿æ¥ Qdrant å¤±è´¥: {e}")
        
        st.divider()

        if all([st.session_state.openai_api_key, st.session_state.openai_base_url, st.session_state.vector_db]):
            st.header("ğŸ“‚ çŸ¥è¯†åº“")
            upload_file = st.file_uploader("ä¸Šä¼ æ³•å¾‹æ–‡ä»¶", type=['pdf'])

            if upload_file:
                if upload_file.name not in st.session_state.processed_files:
                    with st.spinner("æ­£åœ¨å¤„ç†æ–‡æ¡£..."):
                        try:
                            knowledge_base = process_document(upload_file, st.session_state.vector_db)

                            if knowledge_base:
                                st.session_state.knowledge_base = knowledge_base
                                st.session_state.processed_files.add(upload_file.name)
                                legal_researcher = Agent(
                                    name="æ³•å¾‹ç ”ç©¶å‘˜",
                                        role="æ³•å¾‹ç ”ç©¶ä¸“å®¶",
                                        model=OpenAIChat(id="gpt-4.1"),
                                        tools=[DuckDuckGoTools()],
                                        knowledge=st.session_state.knowledge_base,
                                        search_knowledge=True,
                                        instructions=[
                                            "æŸ¥æ‰¾å¹¶å¼•ç”¨ç›¸å…³çš„æ³•å¾‹æ¡ˆä¾‹å’Œå…ˆä¾‹",
                                            "æä¾›è¯¦ç»†çš„ç ”ç©¶æ‘˜è¦å¹¶é™„ä¸Šæ¥æº",
                                            "å¼•ç”¨ä¸Šä¼ æ–‡æ¡£ä¸­çš„å…·ä½“ç« èŠ‚",
                                            "å§‹ç»ˆåœ¨çŸ¥è¯†åº“ä¸­æœç´¢ç›¸å…³ä¿¡æ¯"
                                        ],
                                        markdown=True
                                )

                                contract_analyst = Agent(
                                        name="åˆåŒåˆ†æå¸ˆ",
                                        role="åˆåŒåˆ†æä¸“å®¶",
                                        model=OpenAIChat(id="gpt-4.1"),
                                        knowledge=st.session_state.knowledge_base,
                                        search_knowledge=True,
                                        instructions=[
                                            "ä»”ç»†å®¡æŸ¥åˆåŒ",
                                            "è¯†åˆ«å…³é”®æ¡æ¬¾å’Œæ½œåœ¨é—®é¢˜",
                                            "å¼•ç”¨æ–‡æ¡£ä¸­çš„å…·ä½“æ¡æ¬¾"
                                        ],
                                        markdown=True
                                    )

                                legal_strategist = Agent(
                                    name="æ³•å¾‹ç­–ç•¥å¸ˆ", 
                                    role="æ³•å¾‹ç­–ç•¥ä¸“å®¶",
                                    model=OpenAIChat(id="gpt-4.1"),
                                    knowledge=st.session_state.knowledge_base,
                                    search_knowledge=True,
                                    instructions=[
                                        "åˆ¶å®šå…¨é¢çš„æ³•å¾‹ç­–ç•¥",
                                        "æä¾›å¯è¡Œçš„å»ºè®®",
                                        "åŒæ—¶è€ƒè™‘é£é™©å’Œæœºé‡"
                                    ],
                                    markdown=True
                                )

                                st.session_state.legal_team = Team(
                                    name = "æ³•å¾‹å›¢é˜Ÿè´Ÿè´£äºº",
                                    role="æ³•å¾‹å›¢é˜Ÿåè°ƒå‘˜",
                                    model=OpenAIChat(id="gpt-4.1"),
                                    members=[legal_researcher, contract_analyst, legal_strategist],
                                    knowledge=st.session_state.knowledge_base,
                                    search_knowledge=True,
                                    instructions=[
                                    "åè°ƒå›¢é˜Ÿæˆå‘˜ä¹‹é—´çš„åˆ†æ",
                                            "æä¾›å…¨é¢çš„å›åº”",
                                            "ç¡®ä¿æ‰€æœ‰å»ºè®®éƒ½æœ‰é€‚å½“çš„æ¥æº",
                                            "å¼•ç”¨ä¸Šä¼ æ–‡æ¡£çš„å…·ä½“éƒ¨åˆ†",
                                            "åœ¨å§”æ´¾ä»»åŠ¡ä¹‹å‰å§‹ç»ˆæœç´¢çŸ¥è¯†åº“" 
                                    ],
                                    show_members_responses=True,
                                    markdown=True
                                )

                                st.success("âœ… æ–‡æ¡£å¤„ç†å®Œæ¯•ï¼Œå›¢é˜Ÿå·²åˆå§‹åŒ–ï¼")
                        except Exception as e:
                            st.error(f"å¤„ç†æ–‡æ¡£æ—¶å‡ºé”™: {str(e)}")
                else:
                    st.success("âœ… æ–‡æ¡£å·²å¤„ç†ï¼Œå›¢é˜Ÿå·²å‡†å¤‡å°±ç»ªï¼")
            st.divider()
            st.header("ğŸ” åˆ†æé€‰é¡¹")
            analysis_type = st.selectbox(
                "é€‰æ‹©åˆ†æç±»å‹",
                [
                    "åˆåŒå®¡æŸ¥",
                    "æ³•å¾‹ç ”ç©¶",
                    "é£é™©è¯„ä¼°",
                    "åˆè§„æ€§æ£€æŸ¥",
                    "è‡ªå®šä¹‰æŸ¥è¯¢"
                ]
            )
        else:
            st.warning("è¯·é…ç½®æ‰€æœ‰ API å‡­æ®ä»¥ç»§ç»­")

    if not all([st.session_state.openai_api_key, st.session_state.vector_db]):
        st.info("ğŸ‘ˆ è¯·åœ¨ä¾§è¾¹æ é…ç½®æ‚¨çš„ API å‡­æ®ä»¥å¼€å§‹")
    elif not upload_file:
        st.info("ğŸ‘ˆ è¯·ä¸Šä¼ æ³•å¾‹æ–‡ä»¶ä»¥å¼€å§‹åˆ†æ")
    elif st.session_state.legal_team:
        # ä¸ºåˆ†æç±»å‹å›¾æ ‡åˆ›å»ºä¸€ä¸ªå­—å…¸
        analysis_icons = {
            "åˆåŒå®¡æŸ¥": "ğŸ“‘",
            "æ³•å¾‹ç ”ç©¶": "ğŸ”",
            "é£é™©è¯„ä¼°": "âš ï¸",
            "åˆè§„æ€§æ£€æŸ¥": "âœ…",
            "è‡ªå®šä¹‰æŸ¥è¯¢": "ğŸ’­"
        }

        st.header(f"{analysis_icons[analysis_type]} {analysis_type} åˆ†æ")

        analysis_configs = {
            "åˆåŒå®¡æŸ¥": {
                "query": "å®¡æŸ¥æ­¤åˆåŒï¼Œå¹¶è¯†åˆ«å…³é”®æ¡æ¬¾ã€ä¹‰åŠ¡å’Œæ½œåœ¨é—®é¢˜ã€‚",
                "agents": ["åˆåŒåˆ†æå¸ˆ"],
                "description": "è¯¦ç»†çš„åˆåŒåˆ†æï¼Œé‡ç‚¹å…³æ³¨æ¡æ¬¾å’Œä¹‰åŠ¡"
            },
            "æ³•å¾‹ç ”ç©¶": {
                "query": "ç ”ç©¶ä¸æ­¤æ–‡ä»¶ç›¸å…³çš„æ¡ˆä¾‹å’Œå…ˆä¾‹ã€‚",
                "agents": ["æ³•å¾‹ç ”ç©¶å‘˜"],
                "description": "ç ”ç©¶ç›¸å…³çš„æ³•å¾‹æ¡ˆä¾‹å’Œå…ˆä¾‹"
            },
            "é£é™©è¯„ä¼°": {
                "query": "åˆ†ææ­¤æ–‡ä»¶ä¸­çš„æ½œåœ¨æ³•å¾‹é£é™©å’Œè´£ä»»ã€‚",
                "agents": ["åˆåŒåˆ†æå¸ˆ", "æ³•å¾‹ç­–ç•¥å¸ˆ"],
                "description": "ç»¼åˆé£é™©åˆ†æå’Œæˆ˜ç•¥è¯„ä¼°"
            },
            "åˆè§„æ€§æ£€æŸ¥": {
                "query": "æ£€æŸ¥æ­¤æ–‡ä»¶çš„ç›‘ç®¡åˆè§„æ€§é—®é¢˜ã€‚",
                "agents": ["æ³•å¾‹ç ”ç©¶å‘˜", "åˆåŒåˆ†æå¸ˆ", "æ³•å¾‹ç­–ç•¥å¸ˆ"],
                "description": "å…¨é¢çš„åˆè§„æ€§åˆ†æ"
            },
            "è‡ªå®šä¹‰æŸ¥è¯¢": {
                "query": None,
                "agents": ["æ³•å¾‹ç ”ç©¶å‘˜", "åˆåŒåˆ†æå¸ˆ", "æ³•å¾‹ç­–ç•¥å¸ˆ"],
                "description": "ä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„æ™ºèƒ½ä½“è¿›è¡Œè‡ªå®šä¹‰åˆ†æ"
            }
        }

        st.info(f"ğŸ“‹ {analysis_configs[analysis_type]['description']}")
        st.write(f"ğŸ¤– å½“å‰æ´»åŠ¨çš„æ³•å¾‹ AI æ™ºèƒ½ä½“: {', '.join(analysis_configs[analysis_type]['agents'])}")  #dictionary!!

        # ç”¨æ­¤ä»£ç æ›¿æ¢ç°æœ‰çš„ user_query éƒ¨åˆ†ï¼š
        if analysis_type == "è‡ªå®šä¹‰æŸ¥è¯¢":
            user_query = st.text_area(
                "è¾“å…¥æ‚¨çš„å…·ä½“æŸ¥è¯¢ï¼š",
                help="æ·»åŠ æ‚¨æƒ³åˆ†æçš„ä»»ä½•å…·ä½“é—®é¢˜æˆ–è¦ç‚¹"
            )
        else:
            user_query = None  # å¯¹äºéè‡ªå®šä¹‰æŸ¥è¯¢ï¼Œè®¾ç½®ä¸ºç©º


        if st.button("åˆ†æ"):
            if analysis_type == "è‡ªå®šä¹‰æŸ¥è¯¢" and not user_query:
                st.warning("è¯·è¾“å…¥æŸ¥è¯¢å†…å®¹")
            else:
                with st.spinner("æ­£åœ¨åˆ†ææ–‡æ¡£..."):
                    try:
                        # ç¡®ä¿è®¾ç½®äº† OpenAI API å¯†é’¥
                        os.environ['OPENAI_API_KEY'] = st.session_state.openai_api_key
                        os.environ["OPENAI_BASE_URL"] = st.session_state.openai_base_url

                        # ç»“åˆé¢„å®šä¹‰æŸ¥è¯¢å’Œç”¨æˆ·æŸ¥è¯¢
                        if analysis_type != "è‡ªå®šä¹‰æŸ¥è¯¢":
                            combined_query = f"""
                            ä½¿ç”¨ä¸Šä¼ çš„æ–‡æ¡£ä½œä¸ºå‚è€ƒï¼š
                            
                            ä¸»è¦åˆ†æä»»åŠ¡: {analysis_configs[analysis_type]['query']}
                            é‡ç‚¹é¢†åŸŸ: {', '.join(analysis_configs[analysis_type]['agents'])}
                            
                            è¯·æœç´¢çŸ¥è¯†åº“å¹¶æä¾›æ–‡æ¡£ä¸­çš„å…·ä½“å‚è€ƒã€‚
                            """
                        else:
                            combined_query = f"""
                            ä½¿ç”¨ä¸Šä¼ çš„æ–‡æ¡£ä½œä¸ºå‚è€ƒï¼š
                            
                            {user_query}
                            
                            è¯·æœç´¢çŸ¥è¯†åº“å¹¶æä¾›æ–‡æ¡£ä¸­çš„å…·ä½“å‚è€ƒã€‚
                            é‡ç‚¹é¢†åŸŸ: {', '.join(analysis_configs[analysis_type]['agents'])}
                            """

                        response = st.session_state.legal_team.run(combined_query)
                        
                        # åœ¨é€‰é¡¹å¡ä¸­æ˜¾ç¤ºç»“æœ
                        tabs = st.tabs(["åˆ†æ", "è¦ç‚¹", "å»ºè®®"])
                        
                        with tabs[0]:
                            st.markdown("### è¯¦ç»†åˆ†æ")
                            if response.content:
                                st.markdown(response.content)
                            else:
                                for message in response.messages:
                                    if message.role == 'assistant' and message.content:
                                        st.markdown(message.content)
                        
                        with tabs[1]:
                            st.markdown("### è¦ç‚¹")
                            key_points_response = st.session_state.legal_team.run(
                                f"""åŸºäºä¹‹å‰çš„åˆ†æï¼š    
                                {response.content}
                                
                                è¯·ç”¨é¡¹ç›®ç¬¦å·æ€»ç»“è¦ç‚¹ã€‚
                                é‡ç‚¹å…³æ³¨æ¥è‡ªä»¥ä¸‹æ–¹é¢çš„è§è§£ï¼š {', '.join(analysis_configs[analysis_type]['agents'])}"""
                            )
                            if key_points_response.content:
                                st.markdown(key_points_response.content)
                            else:
                                for message in key_points_response.messages:
                                    if message.role == 'assistant' and message.content:
                                        st.markdown(message.content)
                        
                        with tabs[2]:
                            st.markdown("### å»ºè®®")
                            recommendations_response = st.session_state.legal_team.run(
                                f"""åŸºäºä¹‹å‰çš„åˆ†æï¼š
                                {response.content}
                                
                                æ ¹æ®åˆ†æï¼Œæ‚¨çš„ä¸»è¦å»ºè®®æ˜¯ä»€ä¹ˆï¼Œæœ€ä½³è¡ŒåŠ¨æ–¹æ¡ˆæ˜¯ä»€ä¹ˆï¼Ÿ
                                æä¾›æ¥è‡ªä»¥ä¸‹æ–¹é¢çš„å…·ä½“å»ºè®®ï¼š {', '.join(analysis_configs[analysis_type]['agents'])}"""
                            )
                            if recommendations_response.content:
                                st.markdown(recommendations_response.content)
                            else:
                                for message in recommendations_response.messages:
                                    if message.role == 'assistant' and message.content:
                                        st.markdown(message.content)

                    except Exception as e:
                        st.error(f"åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
    else:
        st.info("è¯·ä¸Šä¼ æ³•å¾‹æ–‡ä»¶ä»¥å¼€å§‹åˆ†æ")

if __name__=="__main__":
    main()




