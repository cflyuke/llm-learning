{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "637fa850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-dotenv\n",
    "# !pip install openai\"\n",
    "# !pip install --upgrade langchain\n",
    "# !pip install langchain-experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb8fb5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# LangChain Docs\n",
    "from langchain_experimental.agents.agent_toolkits import create_python_agent\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9140182e",
   "metadata": {},
   "source": [
    "## 创建LLM Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b78ca01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OPENAI_API_KEY = \"sk-xxxx\"\n",
    "OPENAI_BASE_URL = \"https://api.zhizengzeng.com/v1\"\n",
    "llm = OpenAI(temperature=0, max_tokens=1000,\n",
    "             openai_api_key = OPENAI_API_KEY, base_url=OPENAI_BASE_URL)\n",
    "llm = ChatOpenAI(temperature=0, max_tokens=4000, model=\"gpt-4o\", \n",
    "                 openai_api_key = OPENAI_API_KEY, base_url=OPENAI_BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd700b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_python_agent(\n",
    "    llm=llm, \n",
    "    tool=PythonREPLTool(),\n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    agent_executor_kwargs={\"handle_parsing_errors\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d529c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = \"./titanic_cleaned.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46db3a74",
   "metadata": {},
   "source": [
    "## 对数据做一个summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2552b97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_summary(agent, data_location):\n",
    "    template_string = \"\"\"\n",
    "    Generate a JSON summary for each column in the dataset located at {location}. \\\n",
    "    The summary should include statistics and information for each column:\n",
    "\n",
    "    You MUST print the above summary in a json format.\n",
    "    What is the final printed value? Only tell me the printed part without any extra information, for example: ','.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "    location_prompt = prompt_template.format_messages(\n",
    "                        location=data_location)\n",
    "    response = agent.run(location_prompt)\n",
    "    data_summary = json.loads(response)\n",
    "    return data_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b95b7c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo generate a JSON summary for each column in the dataset located at `./titanic_cleaned.csv`, I will need to:\n",
      "\n",
      "1. Load the dataset using a library like pandas.\n",
      "2. Calculate statistics and information for each column.\n",
      "3. Format the results into a JSON structure.\n",
      "4. Print the JSON summary.\n",
      "\n",
      "Let's proceed with these steps.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input:\n",
      "```python\n",
      "import pandas as pd\n",
      "import json\n",
      "\n",
      "# Load the dataset\n",
      "df = pd.read_csv('./titanic_cleaned.csv')\n",
      "\n",
      "# Generate summary statistics for each column\n",
      "summary = {}\n",
      "for column in df.columns:\n",
      "    col_data = df[column]\n",
      "    summary[column] = {\n",
      "        'count': col_data.count(),\n",
      "        'mean': col_data.mean() if col_data.dtype in ['float64', 'int64'] else None,\n",
      "        'std': col_data.std() if col_data.dtype in ['float64', 'int64'] else None,\n",
      "        'min': col_data.min() if col_data.dtype in ['float64', 'int64'] else None,\n",
      "        '25%': col_data.quantile(0.25) if col_data.dtype in ['float64', 'int64'] else None,\n",
      "        '50%': col_data.median() if col_data.dtype in ['float64', 'int64'] else None,\n",
      "        '75%': col_data.quantile(0.75) if col_data.dtype in ['float64', 'int64'] else None,\n",
      "        'max': col_data.max() if col_data.dtype in ['float64', 'int64'] else None,\n",
      "        'unique': col_data.nunique() if col_data.dtype == 'object' else None,\n",
      "        'top': col_data.mode()[0] if col_data.dtype == 'object' else None,\n",
      "        'freq': col_data.value_counts().iloc[0] if col_data.dtype == 'object' else None\n",
      "    }\n",
      "\n",
      "# Print the summary in JSON format\n",
      "print(json.dumps(summary, indent=4))\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mTypeError('Object of type int64 is not JSON serializable')\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mIt seems there is a `TypeError` because the JSON serialization does not handle NumPy's `int64` type directly. I need to convert these values to native Python types before serializing to JSON.\n",
      "\n",
      "Let's fix this issue by converting the values to native Python types.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input:\n",
      "```python\n",
      "import pandas as pd\n",
      "import json\n",
      "\n",
      "# Load the dataset\n",
      "df = pd.read_csv('./titanic_cleaned.csv')\n",
      "\n",
      "# Generate summary statistics for each column\n",
      "summary = {}\n",
      "for column in df.columns:\n",
      "    col_data = df[column]\n",
      "    summary[column] = {\n",
      "        'count': int(col_data.count()),\n",
      "        'mean': float(col_data.mean()) if col_data.dtype in ['float64', 'int64'] else None,\n",
      "        'std': float(col_data.std()) if col_data.dtype in ['float64', 'int64'] else None,\n",
      "        'min': float(col_data.min()) if col_data.dtype in ['float64', 'int64'] else None,\n",
      "        '25%': float(col_data.quantile(0.25)) if col_data.dtype in ['float64', 'int64'] else None,\n",
      "        '50%': float(col_data.median()) if col_data.dtype in ['float64', 'int64'] else None,\n",
      "        '75%': float(col_data.quantile(0.75)) if col_data.dtype in ['float64', 'int64'] else None,\n",
      "        'max': float(col_data.max()) if col_data.dtype in ['float64', 'int64'] else None,\n",
      "        'unique': int(col_data.nunique()) if col_data.dtype == 'object' else None,\n",
      "        'top': col_data.mode()[0] if col_data.dtype == 'object' else None,\n",
      "        'freq': int(col_data.value_counts().iloc[0]) if col_data.dtype == 'object' else None\n",
      "    }\n",
      "\n",
      "# Print the summary in JSON format\n",
      "print(json.dumps(summary, indent=4))\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{\n",
      "    \"PassengerId\": {\n",
      "        \"count\": 891,\n",
      "        \"mean\": 446.0,\n",
      "        \"std\": 257.3538420152301,\n",
      "        \"min\": 1.0,\n",
      "        \"25%\": 223.5,\n",
      "        \"50%\": 446.0,\n",
      "        \"75%\": 668.5,\n",
      "        \"max\": 891.0,\n",
      "        \"unique\": null,\n",
      "        \"top\": null,\n",
      "        \"freq\": null\n",
      "    },\n",
      "    \"Survived\": {\n",
      "        \"count\": 891,\n",
      "        \"mean\": 0.3838383838383838,\n",
      "        \"std\": 0.4865924542648575,\n",
      "        \"min\": 0.0,\n",
      "        \"25%\": 0.0,\n",
      "        \"50%\": 0.0,\n",
      "        \"75%\": 1.0,\n",
      "        \"max\": 1.0,\n",
      "        \"unique\": null,\n",
      "        \"top\": null,\n",
      "        \"freq\": null\n",
      "    },\n",
      "    \"Pclass\": {\n",
      "        \"count\": 891,\n",
      "        \"mean\": 2.308641975308642,\n",
      "        \"std\": 0.836071240977049,\n",
      "        \"min\": 1.0,\n",
      "        \"25%\": 2.0,\n",
      "        \"50%\": 3.0,\n",
      "        \"75%\": 3.0,\n",
      "        \"max\": 3.0,\n",
      "        \"unique\": null,\n",
      "        \"top\": null,\n",
      "        \"freq\": null\n",
      "    },\n",
      "    \"Name\": {\n",
      "        \"count\": 891,\n",
      "        \"mean\": null,\n",
      "        \"std\": null,\n",
      "        \"min\": null,\n",
      "        \"25%\": null,\n",
      "        \"50%\": null,\n",
      "        \"75%\": null,\n",
      "        \"max\": null,\n",
      "        \"unique\": 891,\n",
      "        \"top\": \"Abbing, Mr. Anthony\",\n",
      "        \"freq\": 1\n",
      "    },\n",
      "    \"Sex\": {\n",
      "        \"count\": 891,\n",
      "        \"mean\": null,\n",
      "        \"std\": null,\n",
      "        \"min\": null,\n",
      "        \"25%\": null,\n",
      "        \"50%\": null,\n",
      "        \"75%\": null,\n",
      "        \"max\": null,\n",
      "        \"unique\": 2,\n",
      "        \"top\": \"male\",\n",
      "        \"freq\": 577\n",
      "    },\n",
      "    \"Age\": {\n",
      "        \"count\": 891,\n",
      "        \"mean\": 29.69911764705882,\n",
      "        \"std\": 13.002015226002882,\n",
      "        \"min\": 0.42,\n",
      "        \"25%\": 22.0,\n",
      "        \"50%\": 29.69911764705882,\n",
      "        \"75%\": 35.0,\n",
      "        \"max\": 80.0,\n",
      "        \"unique\": null,\n",
      "        \"top\": null,\n",
      "        \"freq\": null\n",
      "    },\n",
      "    \"SibSp\": {\n",
      "        \"count\": 891,\n",
      "        \"mean\": 0.5230078563411896,\n",
      "        \"std\": 1.1027434322934317,\n",
      "        \"min\": 0.0,\n",
      "        \"25%\": 0.0,\n",
      "        \"50%\": 0.0,\n",
      "        \"75%\": 1.0,\n",
      "        \"max\": 8.0,\n",
      "        \"unique\": null,\n",
      "        \"top\": null,\n",
      "        \"freq\": null\n",
      "    },\n",
      "    \"Parch\": {\n",
      "        \"count\": 891,\n",
      "        \"mean\": 0.38159371492704824,\n",
      "        \"std\": 0.8060572211299483,\n",
      "        \"min\": 0.0,\n",
      "        \"25%\": 0.0,\n",
      "        \"50%\": 0.0,\n",
      "        \"75%\": 0.0,\n",
      "        \"max\": 6.0,\n",
      "        \"unique\": null,\n",
      "        \"top\": null,\n",
      "        \"freq\": null\n",
      "    },\n",
      "    \"Ticket\": {\n",
      "        \"count\": 891,\n",
      "        \"mean\": null,\n",
      "        \"std\": null,\n",
      "        \"min\": null,\n",
      "        \"25%\": null,\n",
      "        \"50%\": null,\n",
      "        \"75%\": null,\n",
      "        \"max\": null,\n",
      "        \"unique\": 681,\n",
      "        \"top\": \"1601\",\n",
      "        \"freq\": 7\n",
      "    },\n",
      "    \"Fare\": {\n",
      "        \"count\": 891,\n",
      "        \"mean\": 32.204207968574636,\n",
      "        \"std\": 49.6934285971809,\n",
      "        \"min\": 0.0,\n",
      "        \"25%\": 7.9104,\n",
      "        \"50%\": 14.4542,\n",
      "        \"75%\": 31.0,\n",
      "        \"max\": 512.3292,\n",
      "        \"unique\": null,\n",
      "        \"top\": null,\n",
      "        \"freq\": null\n",
      "    },\n",
      "    \"Cabin\": {\n",
      "        \"count\": 891,\n",
      "        \"mean\": null,\n",
      "        \"std\": null,\n",
      "        \"min\": null,\n",
      "        \"25%\": null,\n",
      "        \"50%\": null,\n",
      "        \"75%\": null,\n",
      "        \"max\": null,\n",
      "        \"unique\": 147,\n",
      "        \"top\": \"C92\",\n",
      "        \"freq\": 689\n",
      "    },\n",
      "    \"Embarked\": {\n",
      "        \"count\": 891,\n",
      "        \"mean\": null,\n",
      "        \"std\": null,\n",
      "        \"min\": null,\n",
      "        \"25%\": null,\n",
      "        \"50%\": null,\n",
      "        \"75%\": null,\n",
      "        \"max\": null,\n",
      "        \"unique\": 3,\n",
      "        \"top\": \"S\",\n",
      "        \"freq\": 646\n",
      "    }\n",
      "}\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "\n",
      "Final Answer: {\n",
      "    \"PassengerId\": {\n",
      "        \"count\": 891,\n",
      "        \"mean\": 446.0,\n",
      "        \"std\": 257.3538420152301,\n",
      "        \"min\": 1.0,\n",
      "        \"25%\": 223.5,\n",
      "        \"50%\": 446.0,\n",
      "        \"75%\": 668.5,\n",
      "        \"max\": 891.0,\n",
      "        \"unique\": null,\n",
      "        \"top\": null,\n",
      "        \"freq\": null\n",
      "    },\n",
      "    \"Survived\": {\n",
      "        \"count\": 891,\n",
      "        \"mean\": 0.3838383838383838,\n",
      "        \"std\": 0.4865924542648575,\n",
      "        \"min\": 0.0,\n",
      "        \"25%\": 0.0,\n",
      "        \"50%\": 0.0,\n",
      "        \"75%\": 1.0,\n",
      "        \"max\": 1.0,\n",
      "        \"unique\": null,\n",
      "        \"top\": null,\n",
      "        \"freq\": null\n",
      "    },\n",
      "    \"Pclass\": {\n",
      "        \"count\": 891,\n",
      "        \"mean\": 2.308641975308642,\n",
      "        \"std\": 0.836071240977049,\n",
      "        \"min\": 1.0,\n",
      "        \"25%\": 2.0,\n",
      "        \"50%\": 3.0,\n",
      "        \"75%\": 3.0,\n",
      "        \"max\": 3.0,\n",
      "        \"unique\": null,\n",
      "        \"top\": null,\n",
      "        \"freq\": null\n",
      "    },\n",
      "    \"Name\": {\n",
      "        \"count\": 891,\n",
      "        \"mean\": null,\n",
      "        \"std\": null,\n",
      "        \"min\": null,\n",
      "        \"25%\": null,\n",
      "        \"50%\": null,\n",
      "        \"75%\": null,\n",
      "        \"max\": null,\n",
      "        \"unique\": 891,\n",
      "        \"top\": \"Abbing, Mr. Anthony\",\n",
      "        \"freq\": 1\n",
      "    },\n",
      "    \"Sex\": {\n",
      "        \"count\": 891,\n",
      "        \"mean\": null,\n",
      "        \"std\": null,\n",
      "        \"min\": null,\n",
      "        \"25%\": null,\n",
      "        \"50%\": null,\n",
      "        \"75%\": null,\n",
      "        \"max\": null,\n",
      "        \"unique\": 2,\n",
      "        \"top\": \"male\",\n",
      "        \"freq\": 577\n",
      "    },\n",
      "    \"Age\": {\n",
      "        \"count\": 891,\n",
      "        \"mean\": 29.69911764705882,\n",
      "        \"std\": 13.002015226002882,\n",
      "        \"min\": 0.42,\n",
      "        \"25%\": 22.0,\n",
      "        \"50%\": 29.69911764705882,\n",
      "        \"75%\": 35.0,\n",
      "        \"max\": 80.0,\n",
      "        \"unique\": null,\n",
      "        \"top\": null,\n",
      "        \"freq\": null\n",
      "    },\n",
      "    \"SibSp\": {\n",
      "        \"count\": 891,\n",
      "        \"mean\": 0.5230078563411896,\n",
      "        \"std\": 1.1027434322934317,\n",
      "        \"min\": 0.0,\n",
      "        \"25%\": 0.0,\n",
      "        \"50%\": 0.0,\n",
      "        \"75%\": 1.0,\n",
      "        \"max\": 8.0,\n",
      "        \"unique\": null,\n",
      "        \"top\": null,\n",
      "        \"freq\": null\n",
      "    },\n",
      "    \"Parch\": {\n",
      "        \"count\": 891,\n",
      "        \"mean\": 0.38159371492704824,\n",
      "        \"std\": 0.8060572211299483,\n",
      "        \"min\": 0.0,\n",
      "        \"25%\": 0.0,\n",
      "        \"50%\": 0.0,\n",
      "        \"75%\": 0.0,\n",
      "        \"max\": 6.0,\n",
      "        \"unique\": null,\n",
      "        \"top\": null,\n",
      "        \"freq\": null\n",
      "    },\n",
      "    \"Ticket\": {\n",
      "        \"count\": 891,\n",
      "        \"mean\": null,\n",
      "        \"std\": null,\n",
      "        \"min\": null,\n",
      "        \"25%\": null,\n",
      "        \"50%\": null,\n",
      "        \"75%\": null,\n",
      "        \"max\": null,\n",
      "        \"unique\": 681,\n",
      "        \"top\": \"1601\",\n",
      "        \"freq\": 7\n",
      "    },\n",
      "    \"Fare\": {\n",
      "        \"count\": 891,\n",
      "        \"mean\": 32.204207968574636,\n",
      "        \"std\": 49.6934285971809,\n",
      "        \"min\": 0.0,\n",
      "        \"25%\": 7.9104,\n",
      "        \"50%\": 14.4542,\n",
      "        \"75%\": 31.0,\n",
      "        \"max\": 512.3292,\n",
      "        \"unique\": null,\n",
      "        \"top\": null,\n",
      "        \"freq\": null\n",
      "    },\n",
      "    \"Cabin\": {\n",
      "        \"count\": 891,\n",
      "        \"mean\": null,\n",
      "        \"std\": null,\n",
      "        \"min\": null,\n",
      "        \"25%\": null,\n",
      "        \"50%\": null,\n",
      "        \"75%\": null,\n",
      "        \"max\": null,\n",
      "        \"unique\": 147,\n",
      "        \"top\": \"C92\",\n",
      "        \"freq\": 689\n",
      "    },\n",
      "    \"Embarked\": {\n",
      "        \"count\": 891,\n",
      "        \"mean\": null,\n",
      "        \"std\": null,\n",
      "        \"min\": null,\n",
      "        \"25%\": null,\n",
      "        \"50%\": null,\n",
      "        \"75%\": null,\n",
      "        \"max\": null,\n",
      "        \"unique\": 3,\n",
      "        \"top\": \"S\",\n",
      "        \"freq\": 646\n",
      "    }\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PassengerId': {'count': 891,\n",
       "  'mean': 446.0,\n",
       "  'std': 257.3538420152301,\n",
       "  'min': 1.0,\n",
       "  '25%': 223.5,\n",
       "  '50%': 446.0,\n",
       "  '75%': 668.5,\n",
       "  'max': 891.0,\n",
       "  'unique': None,\n",
       "  'top': None,\n",
       "  'freq': None},\n",
       " 'Survived': {'count': 891,\n",
       "  'mean': 0.3838383838383838,\n",
       "  'std': 0.4865924542648575,\n",
       "  'min': 0.0,\n",
       "  '25%': 0.0,\n",
       "  '50%': 0.0,\n",
       "  '75%': 1.0,\n",
       "  'max': 1.0,\n",
       "  'unique': None,\n",
       "  'top': None,\n",
       "  'freq': None},\n",
       " 'Pclass': {'count': 891,\n",
       "  'mean': 2.308641975308642,\n",
       "  'std': 0.836071240977049,\n",
       "  'min': 1.0,\n",
       "  '25%': 2.0,\n",
       "  '50%': 3.0,\n",
       "  '75%': 3.0,\n",
       "  'max': 3.0,\n",
       "  'unique': None,\n",
       "  'top': None,\n",
       "  'freq': None},\n",
       " 'Name': {'count': 891,\n",
       "  'mean': None,\n",
       "  'std': None,\n",
       "  'min': None,\n",
       "  '25%': None,\n",
       "  '50%': None,\n",
       "  '75%': None,\n",
       "  'max': None,\n",
       "  'unique': 891,\n",
       "  'top': 'Abbing, Mr. Anthony',\n",
       "  'freq': 1},\n",
       " 'Sex': {'count': 891,\n",
       "  'mean': None,\n",
       "  'std': None,\n",
       "  'min': None,\n",
       "  '25%': None,\n",
       "  '50%': None,\n",
       "  '75%': None,\n",
       "  'max': None,\n",
       "  'unique': 2,\n",
       "  'top': 'male',\n",
       "  'freq': 577},\n",
       " 'Age': {'count': 891,\n",
       "  'mean': 29.69911764705882,\n",
       "  'std': 13.002015226002882,\n",
       "  'min': 0.42,\n",
       "  '25%': 22.0,\n",
       "  '50%': 29.69911764705882,\n",
       "  '75%': 35.0,\n",
       "  'max': 80.0,\n",
       "  'unique': None,\n",
       "  'top': None,\n",
       "  'freq': None},\n",
       " 'SibSp': {'count': 891,\n",
       "  'mean': 0.5230078563411896,\n",
       "  'std': 1.1027434322934317,\n",
       "  'min': 0.0,\n",
       "  '25%': 0.0,\n",
       "  '50%': 0.0,\n",
       "  '75%': 1.0,\n",
       "  'max': 8.0,\n",
       "  'unique': None,\n",
       "  'top': None,\n",
       "  'freq': None},\n",
       " 'Parch': {'count': 891,\n",
       "  'mean': 0.38159371492704824,\n",
       "  'std': 0.8060572211299483,\n",
       "  'min': 0.0,\n",
       "  '25%': 0.0,\n",
       "  '50%': 0.0,\n",
       "  '75%': 0.0,\n",
       "  'max': 6.0,\n",
       "  'unique': None,\n",
       "  'top': None,\n",
       "  'freq': None},\n",
       " 'Ticket': {'count': 891,\n",
       "  'mean': None,\n",
       "  'std': None,\n",
       "  'min': None,\n",
       "  '25%': None,\n",
       "  '50%': None,\n",
       "  '75%': None,\n",
       "  'max': None,\n",
       "  'unique': 681,\n",
       "  'top': '1601',\n",
       "  'freq': 7},\n",
       " 'Fare': {'count': 891,\n",
       "  'mean': 32.204207968574636,\n",
       "  'std': 49.6934285971809,\n",
       "  'min': 0.0,\n",
       "  '25%': 7.9104,\n",
       "  '50%': 14.4542,\n",
       "  '75%': 31.0,\n",
       "  'max': 512.3292,\n",
       "  'unique': None,\n",
       "  'top': None,\n",
       "  'freq': None},\n",
       " 'Cabin': {'count': 891,\n",
       "  'mean': None,\n",
       "  'std': None,\n",
       "  'min': None,\n",
       "  '25%': None,\n",
       "  '50%': None,\n",
       "  '75%': None,\n",
       "  'max': None,\n",
       "  'unique': 147,\n",
       "  'top': 'C92',\n",
       "  'freq': 689},\n",
       " 'Embarked': {'count': 891,\n",
       "  'mean': None,\n",
       "  'std': None,\n",
       "  'min': None,\n",
       "  '25%': None,\n",
       "  '50%': None,\n",
       "  '75%': None,\n",
       "  'max': None,\n",
       "  'unique': 3,\n",
       "  'top': 'S',\n",
       "  'freq': 646}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data_summary(agent, data_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d32c9e",
   "metadata": {},
   "source": [
    "## 清洗数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cd19e6",
   "metadata": {},
   "source": [
    "### 缺失值填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fdafba7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_null(agent, data_location):\n",
    "    template_string = \"\"\"\n",
    "    Load the dataset at location: {location} and handle null values on the following conditions:\n",
    "\n",
    "    CONDITION 1: For numerical columns: Replace null values with the mean of the respective column.\n",
    "\n",
    "    CONDITION 2: For string (categorical) columns: Replace null values with random values that are not null from the same column.\n",
    "\n",
    "    You MUST perform data cleaning in the following order:\n",
    "    1. Count how many null values are there in the dataset before data cleaning in each column.\n",
    "    2. Handle null values from each column based on the above conditions\n",
    "    3. Count how many null values are there in the dataset after data cleaning in each column. \n",
    "    4. Save this new data file in the same file from where it was loaded.\n",
    "\n",
    "    What is the count of values that were null before and after this data cleaning in each column? Return the output in a json format \\\n",
    "    where each entry corresponds to the column name followed by the count of null values before and after data cleaning.\n",
    "    You MUST substitute all variables in the dataset before replying.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "    location_prompt = prompt_template.format_messages(location=data_location)\n",
    "    response = agent.run(location_prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a366b7a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo answer this question, I need to perform the following steps:\n",
      "\n",
      "1. Load the dataset from the specified location.\n",
      "2. Count the number of null values in each column before cleaning.\n",
      "3. Handle null values according to the specified conditions:\n",
      "   - For numerical columns, replace null values with the mean of the column.\n",
      "   - For categorical columns, replace null values with random non-null values from the same column.\n",
      "4. Count the number of null values in each column after cleaning.\n",
      "5. Save the cleaned dataset back to the original file.\n",
      "6. Return the count of null values before and after cleaning in a JSON format.\n",
      "\n",
      "Let's start by loading the dataset and counting the null values before cleaning.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input: \n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Load the dataset\n",
      "file_path = './titanic_cleaned.csv'\n",
      "df = pd.read_csv(file_path)\n",
      "\n",
      "# Count null values before cleaning\n",
      "null_counts_before = df.isnull().sum().to_dict()\n",
      "print(null_counts_before)\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'PassengerId': 0, 'Survived': 0, 'Pclass': 0, 'Name': 0, 'Sex': 0, 'Age': 0, 'SibSp': 0, 'Parch': 0, 'Ticket': 0, 'Fare': 0, 'Cabin': 0, 'Embarked': 0}\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe dataset does not contain any null values in any of the columns before cleaning. However, I will proceed with the data cleaning steps as specified to ensure the process is complete and verify the results.\n",
      "\n",
      "Next, I will handle null values according to the specified conditions and then count the null values after cleaning.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input: \n",
      "```python\n",
      "import numpy as np\n",
      "\n",
      "# Function to fill null values in numerical columns with the mean\n",
      "def fill_numerical_with_mean(df):\n",
      "    for column in df.select_dtypes(include=[np.number]).columns:\n",
      "        mean_value = df[column].mean()\n",
      "        df[column].fillna(mean_value, inplace=True)\n",
      "\n",
      "# Function to fill null values in categorical columns with random non-null values\n",
      "def fill_categorical_with_random(df):\n",
      "    for column in df.select_dtypes(include=[object]).columns:\n",
      "        non_null_values = df[column].dropna().unique()\n",
      "        df[column] = df[column].apply(lambda x: np.random.choice(non_null_values) if pd.isnull(x) else x)\n",
      "\n",
      "# Apply the functions to handle null values\n",
      "fill_numerical_with_mean(df)\n",
      "fill_categorical_with_random(df)\n",
      "\n",
      "# Count null values after cleaning\n",
      "null_counts_after = df.isnull().sum().to_dict()\n",
      "print(null_counts_after)\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'PassengerId': 0, 'Survived': 0, 'Pclass': 0, 'Name': 0, 'Sex': 0, 'Age': 0, 'SibSp': 0, 'Parch': 0, 'Ticket': 0, 'Fare': 0, 'Cabin': 0, 'Embarked': 0}\n",
      "\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThe dataset did not contain any null values before cleaning, and as expected, there are no null values after the cleaning process either. Therefore, the count of null values before and after cleaning remains the same for each column.\n",
      "\n",
      "Now, I will save the cleaned dataset back to the original file and provide the final JSON output with the count of null values before and after cleaning.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input: \n",
      "```python\n",
      "# Save the cleaned dataset back to the original file\n",
      "df.to_csv(file_path, index=False)\n",
      "\n",
      "# Prepare the final JSON output\n",
      "null_counts = {column: {\"before\": null_counts_before[column], \"after\": null_counts_after[column]} for column in df.columns}\n",
      "print(null_counts)\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'PassengerId': {'before': 0, 'after': 0}, 'Survived': {'before': 0, 'after': 0}, 'Pclass': {'before': 0, 'after': 0}, 'Name': {'before': 0, 'after': 0}, 'Sex': {'before': 0, 'after': 0}, 'Age': {'before': 0, 'after': 0}, 'SibSp': {'before': 0, 'after': 0}, 'Parch': {'before': 0, 'after': 0}, 'Ticket': {'before': 0, 'after': 0}, 'Fare': {'before': 0, 'after': 0}, 'Cabin': {'before': 0, 'after': 0}, 'Embarked': {'before': 0, 'after': 0}}\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "\n",
      "Final Answer: {'PassengerId': {'before': 0, 'after': 0}, 'Survived': {'before': 0, 'after': 0}, 'Pclass': {'before': 0, 'after': 0}, 'Name': {'before': 0, 'after': 0}, 'Sex': {'before': 0, 'after': 0}, 'Age': {'before': 0, 'after': 0}, 'SibSp': {'before': 0, 'after': 0}, 'Parch': {'before': 0, 'after': 0}, 'Ticket': {'before': 0, 'after': 0}, 'Fare': {'before': 0, 'after': 0}, 'Cabin': {'before': 0, 'after': 0}, 'Embarked': {'before': 0, 'after': 0}}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"{'PassengerId': {'before': 0, 'after': 0}, 'Survived': {'before': 0, 'after': 0}, 'Pclass': {'before': 0, 'after': 0}, 'Name': {'before': 0, 'after': 0}, 'Sex': {'before': 0, 'after': 0}, 'Age': {'before': 0, 'after': 0}, 'SibSp': {'before': 0, 'after': 0}, 'Parch': {'before': 0, 'after': 0}, 'Ticket': {'before': 0, 'after': 0}, 'Fare': {'before': 0, 'after': 0}, 'Cabin': {'before': 0, 'after': 0}, 'Embarked': {'before': 0, 'after': 0}}\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_null(agent, data_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bc7ac0",
   "metadata": {},
   "source": [
    "## 查询还有多少NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f8001d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_query(agent, data_location, query):\n",
    "    template_string = \"\"\"\n",
    "    Answer the following query on the dataset location given below.\n",
    "    Reply with all the relevant information.\n",
    "\n",
    "    location: {location}\n",
    "    query: {query}\n",
    "    \"\"\"\n",
    "    prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "    location_prompt = prompt_template.format_messages(location=data_location, query=query)\n",
    "    response = agent.run(location_prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48e5dc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo answer the question, I need to load the dataset from the specified location and then check for null values in each column. I'll use the pandas library to accomplish this.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input:\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Load the dataset\n",
      "df = pd.read_csv('./titanic_cleaned.csv')\n",
      "\n",
      "# Check for null values in each column\n",
      "null_values = df.isnull().sum()\n",
      "print(null_values)\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Cabin          0\n",
      "Embarked       0\n",
      "dtype: int64\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "\n",
      "Final Answer: There are no null values in any column of the dataset.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"How many null values are there in each column of the dataset?\"\n",
    "response = answer_query(agent, data_location, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb61a8ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are no null values in any column of the dataset.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096d0da2",
   "metadata": {},
   "source": [
    "## 对数据画图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9db7d136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure(agent, data_location, plot_type, columns):\n",
    "    template_string = \"\"\"\n",
    "    Plot a figure of the plot type given below between the columns as mentioned below\\\n",
    "    form the data set at the below location:\n",
    "\n",
    "    location: {location}\n",
    "    plot_type: {plot_type}\n",
    "    columns: {columns}\n",
    "    \n",
    "    Assume that any required library is already installed\n",
    "    \"\"\"\n",
    "    prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "    location_prompt = prompt_template.format_messages(location=data_location, plot_type = plot_type, columns = columns)\n",
    "    response = agent.run(location_prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef4c4f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo plot a bar chart for the 'Survived' column from the dataset located at './titanic_cleaned.csv', I will follow these steps:\n",
      "\n",
      "1. Import the necessary libraries.\n",
      "2. Load the dataset from the specified location.\n",
      "3. Plot a bar chart for the 'Survived' column.\n",
      "\n",
      "Let's execute these steps.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input:\n",
      "```python\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Load the dataset\n",
      "data = pd.read_csv('./titanic_cleaned.csv')\n",
      "\n",
      "# Plot a bar chart for the 'Survived' column\n",
      "data['Survived'].value_counts().plot(kind='bar')\n",
      "plt.title('Survival Count')\n",
      "plt.xlabel('Survived')\n",
      "plt.ylabel('Count')\n",
      "plt.show()\n",
      "```\u001b[0m"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI don't know\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI don't know\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI don't know\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI don't know\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI don't know\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI don't know\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI don't know\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI don't know\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI don't know\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI don't know\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI don't know\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI don't know\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI don't know\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI don't know\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "plot_type = \"bar\"\n",
    "columns=['Survived']\n",
    "response = plot_figure(agent, data_location, plot_type, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0894e3b3",
   "metadata": {},
   "source": [
    "## 模型训练和预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "39108f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_run(agent, data_location, query):\n",
    "    template_string = \"\"\"\n",
    "    Based on the given query, create a model using the SKLearn Library of Python\\\n",
    "    Train the model on the dataset at the given location.\n",
    "    Then, Based on the remaining information in the query, predict the output value for the new input.\n",
    "\n",
    "    location: {location}\n",
    "    query: {query}\n",
    "    \n",
    "    Reply with the predicted value for the new input.\n",
    "    \"\"\"\n",
    "    prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "    location_prompt = prompt_template.format_messages(location=data_location,query=query)\n",
    "    response = agent.run(location_prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fc802fe6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo answer this question, I need to perform the following steps:\n",
      "\n",
      "1. Load the dataset from the specified location.\n",
      "2. Preprocess the data to select the relevant features: Sex, Age, Fare, and Pclass.\n",
      "3. Split the data into training and test sets.\n",
      "4. Train a Support Vector Machine (SVM) model using the training data.\n",
      "5. Evaluate the model on the test set and report the accuracy.\n",
      "6. Use the trained model to predict the survival of Mr. Henry, a 22-year-old male in 1st class who paid 75 dollars.\n",
      "\n",
      "Let's start by loading the dataset and preprocessing it.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input:\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Load the dataset\n",
      "data = pd.read_csv('./titanic_cleaned.csv')\n",
      "\n",
      "# Display the first few rows of the dataset to understand its structure\n",
      "print(data.head())\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   C92        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   C92        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   C92        S  \n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe dataset has been successfully loaded. The relevant columns for our task are 'Sex', 'Age', 'Fare', and 'Pclass'. We also need to encode the 'Sex' column to numerical values for the model to process it. Let's proceed with preprocessing the data, splitting it into training and test sets, and then training the SVM model.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input:\n",
      "```python\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.preprocessing import LabelEncoder\n",
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "# Select relevant features and target\n",
      "features = data[['Sex', 'Age', 'Fare', 'Pclass']]\n",
      "target = data['Survived']\n",
      "\n",
      "# Encode 'Sex' column\n",
      "le = LabelEncoder()\n",
      "features['Sex'] = le.fit_transform(features['Sex'])\n",
      "\n",
      "# Handle missing values by filling them with the median\n",
      "features['Age'].fillna(features['Age'].median(), inplace=True)\n",
      "\n",
      "# Split the data into training and test sets\n",
      "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
      "\n",
      "# Train the SVM model\n",
      "svm_model = SVC()\n",
      "svm_model.fit(X_train, y_train)\n",
      "\n",
      "# Evaluate the model on the test set\n",
      "y_pred = svm_model.predict(X_test)\n",
      "accuracy = accuracy_score(y_test, y_pred)\n",
      "\n",
      "print(f\"Test Accuracy: {accuracy}\")\n",
      "```\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<string>:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "<string>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mTest Accuracy: 0.6536312849162011\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe SVM model has been trained and evaluated, achieving a test accuracy of approximately 65.36%. Now, let's use the trained model to predict whether Mr. Henry, a 22-year-old male in 1st class who paid 75 dollars, survived or not.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input:\n",
      "```python\n",
      "# Prepare the input data for Mr. Henry\n",
      "mr_henry = pd.DataFrame({\n",
      "    'Sex': [le.transform(['male'])[0]],  # Encode 'male' to numerical value\n",
      "    'Age': [22],\n",
      "    'Fare': [75],\n",
      "    'Pclass': [1]\n",
      "})\n",
      "\n",
      "# Predict the survival of Mr. Henry\n",
      "mr_henry_prediction = svm_model.predict(mr_henry)\n",
      "\n",
      "# Output the prediction\n",
      "mr_henry_survived = \"Survived\" if mr_henry_prediction[0] == 1 else \"Did not survive\"\n",
      "print(mr_henry_survived)\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mSurvived\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "\n",
      "Final Answer: Mr. Henry survived.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Mr. Henry survived.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Train a support vector machine model with default parameters,\\\n",
    "where we want to predict the weather the Person survived or died. \\\n",
    "Use the location specified for training, predict only using the Sex, Age, Fare, and Pclass columns. \\\n",
    "Split the data into training and test sets, and report the test accuracy. Then \\\n",
    "predict if a person if Mr. Henry, a 22 year old male living in a 1st class suite, cabin 23 and paid 75 dollars survived or not.\"\n",
    "train_run(agent, data_location, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c430c38b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo answer this question, I need to perform the following steps:\n",
      "\n",
      "1. Load the dataset from the specified location.\n",
      "2. Prepare the data by selecting the relevant features: 'Sex', 'Age', 'Fare', and 'Pclass'.\n",
      "3. Encode categorical variables if necessary (e.g., 'Sex').\n",
      "4. Split the data into training and test sets.\n",
      "5. Train a Random Forest Classifier using the training data.\n",
      "6. Evaluate the model on the test set and report the accuracy.\n",
      "7. Use the trained model to predict the survival of Mr. Henry based on the given features.\n",
      "\n",
      "Let's start by loading the dataset and preparing the data.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input:\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Load the dataset\n",
      "data = pd.read_csv('./titanic_cleaned.csv')\n",
      "\n",
      "# Display the first few rows of the dataset to understand its structure\n",
      "print(data.head())\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   C92        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   C92        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   C92        S  \n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe dataset has been loaded successfully. Now, I need to prepare the data by selecting the relevant features: 'Sex', 'Age', 'Fare', and 'Pclass'. Additionally, I need to encode the 'Sex' column as it is a categorical variable.\n",
      "\n",
      "Let's proceed with data preparation and encoding.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input:\n",
      "```python\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.preprocessing import LabelEncoder\n",
      "\n",
      "# Select relevant features and target variable\n",
      "features = data[['Sex', 'Age', 'Fare', 'Pclass']]\n",
      "target = data['Survived']\n",
      "\n",
      "# Encode the 'Sex' column\n",
      "label_encoder = LabelEncoder()\n",
      "features['Sex'] = label_encoder.fit_transform(features['Sex'])\n",
      "\n",
      "# Check the prepared features\n",
      "print(features.head())\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m   Sex   Age     Fare  Pclass\n",
      "0    1  22.0   7.2500       3\n",
      "1    0  38.0  71.2833       1\n",
      "2    0  26.0   7.9250       3\n",
      "3    0  35.0  53.1000       1\n",
      "4    1  35.0   8.0500       3\n",
      "\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThe data preparation is complete. The 'Sex' column has been encoded, and the relevant features have been selected. Now, I need to split the data into training and test sets, train a Random Forest Classifier, evaluate its accuracy on the test set, and finally predict the survival of Mr. Henry.\n",
      "\n",
      "Let's proceed with these steps.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input:\n",
      "```python\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "# Split the data into training and test sets\n",
      "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
      "\n",
      "# Train a Random Forest Classifier\n",
      "rf_classifier = RandomForestClassifier(random_state=42)\n",
      "rf_classifier.fit(X_train, y_train)\n",
      "\n",
      "# Evaluate the model on the test set\n",
      "y_pred = rf_classifier.predict(X_test)\n",
      "test_accuracy = accuracy_score(y_test, y_pred)\n",
      "\n",
      "# Print the test accuracy\n",
      "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mTest Accuracy: 0.79\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe Random Forest Classifier has been trained, and the test accuracy is approximately 79%. Now, I need to use the trained model to predict whether Mr. Henry survived or not, based on the given features: a 22-year-old male living in a 1st class suite who paid 75 dollars.\n",
      "\n",
      "Let's proceed with making this prediction.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input:\n",
      "```python\n",
      "# Prepare the input data for Mr. Henry\n",
      "mr_henry_features = pd.DataFrame({\n",
      "    'Sex': [label_encoder.transform(['male'])[0]],  # Encode 'male' using the same label encoder\n",
      "    'Age': [22],\n",
      "    'Fare': [75],\n",
      "    'Pclass': [1]\n",
      "})\n",
      "\n",
      "# Predict the survival of Mr. Henry\n",
      "mr_henry_prediction = rf_classifier.predict(mr_henry_features)\n",
      "\n",
      "# Print the prediction result\n",
      "print(\"Mr. Henry Survived\" if mr_henry_prediction[0] == 1 else \"Mr. Henry Did Not Survive\")\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mMr. Henry Did Not Survive\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "\n",
      "Final Answer: Mr. Henry Did Not Survive.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Mr. Henry Did Not Survive.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Train a random forest classifier model with default parameters,\\\n",
    "where we want to predict the weather the Person survived or died. \\\n",
    "Use the location specified for training, predict only using the Sex, Age, Fare, and Pclass columns. \\\n",
    "Split the data into training and test sets, and report the test accuracy. Then \\\n",
    "predict if a person if Mr. Henry, a 22 year old male living in a 1st class suite, cabin 23 and paid 75 dollars survived or not.\"\n",
    "train_run(agent, data_location, query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
