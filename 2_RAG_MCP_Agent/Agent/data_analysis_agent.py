import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import operator
import os
import joblib
from langchain_core.tools import tool
from langchain.chat_models import init_chat_model
from langgraph.graph import StateGraph, MessagesState, END, START
from langchain_core.messages import SystemMessage, ToolMessage, HumanMessage
from dotenv import load_dotenv

load_dotenv()
os.environ["OPENAI_API_KEY"] = os.getenv("API_KEY", "")
os.environ["OPENAI_BASE_URL"] = os.getenv("BASE_URL", "")

@tool
def data_statistics(path: str) -> str:
    """åŠ è½½CSVæ–‡ä»¶å¹¶è¿”å›åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯å’Œæ•°æ®å†…å®¹ã€‚
    Args:
        path: str : CSVæ–‡ä»¶çš„è·¯å¾„
    """
    df = pd.read_csv(path)
    stats = df.describe().to_string()
    head = df.head().to_string()
    return f"æ•°æ®é¢„è§ˆ:\n{head}\n\næ•°æ®ç»Ÿè®¡ä¿¡æ¯:\n{stats}\n"

@tool
def plot_correlation_heatmap(path:str, output_path: str) -> str:
    """ç”Ÿæˆå¹¶ä¿å­˜CSVæ–‡ä»¶çš„ç›¸å…³æ€§çƒ­åŠ›å›¾ã€‚
    Args:
        path: str : CSVæ–‡ä»¶çš„è·¯å¾„
        output_path: str : çƒ­åŠ›å›¾ä¿å­˜è·¯å¾„
    """
    df = pd.read_csv(path)
    numerical_cols = df.select_dtypes(include=['number']).columns
    corr_matrix = df[numerical_cols].corr()

    plt.figure(figsize=(10, 8))
    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f")
    plt.title('Relative Heatmap')
    plt.savefig(output_path)
    plt.close()
    return f"ç›¸å…³æ€§çƒ­åŠ›å›¾å·²ä¿å­˜è‡³ {output_path}"


def preprocess_titanic_data(df: pd.DataFrame) -> pd.DataFrame:
    """é¢„å¤„ç†Titanicæ•°æ®é›†ã€‚
    å‚æ•°:
        df: pd.DataFrame : è¾“å…¥çš„æ•°æ®å¸§
    """
    df['Age'] = df['Age'].fillna(df['Age'].median())
    df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])
    df['Fare'] = df['Fare'].fillna(df['Fare'].median())
    
    df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})
    df['Embarked'] = df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})

    features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']
    return df[features]

@tool
def train_model(path: str, output_model_path: str) -> str:
    """åœ¨Titanicæ•°æ®é›†ä¸Šè®­ç»ƒRandomForestæ¨¡å‹å¹¶ä¿å­˜ã€‚
    Args:
        path: str : CSVæ–‡ä»¶çš„è·¯å¾„
        output_model_path: str : è®­ç»ƒå¥½çš„æ¨¡å‹ä¿å­˜è·¯å¾„
    """
    df = pd.read_csv(path)
    X = preprocess_titanic_data(df)
    y = df['Survived']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # æ¨¡å‹è®­ç»ƒ
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    
    # æ¨¡å‹è¯„ä¼°
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)

    joblib.dump(model, output_model_path)
    feature_importance = dict(zip(X.columns, model.feature_importances_))
    sorted_features = dict(sorted(feature_importance.items(), key=operator.itemgetter(1), reverse=True))
    
    return f"""æ¨¡å‹å·²è®­ç»ƒå¹¶ä¿å­˜åˆ° {output_model_path}
æµ‹è¯•å‡†ç¡®ç‡: {accuracy:.2f}
ç‰¹å¾é‡è¦æ€§:
{sorted_features}"""

@tool
def predict_survival(model_path: str, passenger_data: dict) -> str:
    """é¢„æµ‹ä¹˜å®¢çš„ç”Ÿå­˜æ¦‚ç‡ã€‚
    å‚æ•°:
        model_path: str : ä¿å­˜çš„æ¨¡å‹è·¯å¾„
        passenger_data: dict : ä¹˜å®¢ä¿¡æ¯å­—å…¸
    """
    # åŠ è½½æ¨¡å‹
    model = joblib.load(model_path)
    df = pd.DataFrame([passenger_data])
    # é¢„å¤„ç†æ•°æ®
    X = preprocess_titanic_data(df)
    probability = model.predict_proba(X)[0]
    prediction = model.predict(X)[0]
    
    return f"""ç”Ÿå­˜é¢„æµ‹ç»“æœ: {"å­˜æ´»" if prediction == 1 else "æœªå­˜æ´»"}
ç”Ÿå­˜æ¦‚ç‡: {probability[1]:.2f}"""


class ChatBot:
    def __init__(self):
        self.tools = [data_statistics, plot_correlation_heatmap, train_model, predict_survival]
        self.name2tool = {tool.name: tool for tool in self.tools}
        
        # åˆå§‹åŒ–LLM
        self.llm_model = init_chat_model(model="gpt-4.1", temperature=0.5).bind_tools(self.tools)
        
        # åˆå§‹åŒ–å¯¹è¯çŠ¶æ€
        self.conversation_history = []
        self.system_message = SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æåŠ©æ‰‹ï¼Œèƒ½å¤Ÿå¸®ç”¨æˆ·åšæ•°æ®åˆ†æã€‚ä½ å¯ä»¥è¿›è¡Œæ•°æ®ç»Ÿè®¡åˆ†æã€ç»˜åˆ¶ç›¸å…³æ€§çƒ­åŠ›å›¾ã€è®­ç»ƒæ¨¡å‹å’Œé¢„æµ‹ã€‚è¯·ä¿æŒå¯¹è¯çš„è¿ç»­æ€§ï¼Œè®°ä½ä¹‹å‰çš„ä¸Šä¸‹æ–‡ã€‚")
        
        # æ„å»ºAgent
        self.agent = self._build_agent()
    
    def _build_agent(self):
        def llm_node(state: MessagesState):
            # åˆå¹¶å†å²è®°å½•å’Œå½“å‰æ¶ˆæ¯
            all_messages = [self.system_message] + self.conversation_history + state["messages"]
            response = self.llm_model.invoke(all_messages)
            return {"messages": [response]}
        
        def tool_node(state: MessagesState):
            result = []
            for tool_call in state["messages"][-1].tool_calls:
                tool = self.name2tool[tool_call["name"]]
                tool_result = tool.invoke(tool_call["args"])
                result.append(
                    ToolMessage(
                        content=tool_result,
                        tool_call_id=tool_call["id"]
                    )
                )
            return {"messages": result}
        
        def should_continue(state: MessagesState):
            last_message = state["messages"][-1]
            if last_message.tool_calls:
                return "tool_node"
            return END
        
        # æ„å»ºå·¥ä½œæµç¨‹å›¾
        agent_builder = StateGraph(MessagesState)
        agent_builder.add_node("llm_node", llm_node)
        agent_builder.add_node("tool_node", tool_node)
        agent_builder.add_edge(START, "llm_node")
        agent_builder.add_edge("tool_node", "llm_node")
        agent_builder.add_conditional_edges("llm_node", should_continue, ["tool_node", END])
        
        return agent_builder.compile()
    
    def chat(self, user_input: str) -> str:
        """å¤„ç†ç”¨æˆ·è¾“å…¥å¹¶è¿”å›å›å¤
        
        å‚æ•°:
            user_input: str : ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯
        è¿”å›:
            str : åŠ©æ‰‹çš„å›å¤
        """
        # åˆ›å»ºç”¨æˆ·æ¶ˆæ¯
        user_message = HumanMessage(content=user_input)
        
        # è¿è¡Œagent
        result = self.agent.invoke({"messages": [user_message]})
        
        # æ›´æ–°å¯¹è¯å†å²
        self.conversation_history.extend([user_message] + result["messages"])
        
        # è¿”å›æœ€åä¸€æ¡æ¶ˆæ¯çš„å†…å®¹
        return result["messages"][-1].content
    
    def clear_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self.conversation_history = []

if __name__ == "__main__":
    chatbot = ChatBot()
    print("ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„æ•°æ®åˆ†æåŠ©æ‰‹ ğŸ¤– (è¾“å…¥ 'exit' é€€å‡º, 'clear' æ¸…ç©ºå†å²): ")
    
    while True:
        user_input = input("ä½ ï¼š")
        if user_input.lower() == 'exit':
            break
        elif user_input.lower() == 'clear':
            chatbot.clear_history()
            print("å¯¹è¯å†å²å·²æ¸…ç©º")
            continue
        response = chatbot.chat(user_input)
        print(f"ğŸ¤–ï¼š{response}")








